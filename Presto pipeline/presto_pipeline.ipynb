{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58cb1373-d425-405b-a417-3373f3885d86",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "import re\n",
    "\n",
    "# --- 1. CONFIGURATION ---\n",
    "# The raw data file is in our current directory\n",
    "raw_filename = \"bpsr100613_052818_beam08.sf\"\n",
    "\n",
    "# The base name for all the output files rfifind will create\n",
    "output_basename = \"bpsr100613_beam08\"\n",
    "\n",
    "# --- 2. DEFINE EXPECTED OUTPUT & PRE-EXECUTION CHECK ---\n",
    "# We know rfifind creates several files, but the .mask file is the key output.\n",
    "# We will check for its existence to decide whether to run the command.\n",
    "mask_filename = output_basename + \"_rfifind.mask\"\n",
    "\n",
    "print(f\"Checking for existing output file: '{mask_filename}'\")\n",
    "\n",
    "# If the mask file already exists, we skip the execution step.\n",
    "if os.path.exists(mask_filename):\n",
    "    print(\"‚úÖ Files found. Skipping rfifind execution.\")\n",
    "\n",
    "# If the file does not exist, then we run the command.\n",
    "else:\n",
    "    # --- 3. EXECUTION ---\n",
    "    print(f\"\\nFile not found. Starting RFI analysis on: {raw_filename}\")\n",
    "    try:\n",
    "        command = [\n",
    "            \"rfifind\",\n",
    "            \n",
    "            # --- PHYSICAL PARAMETERS ---\n",
    "            #\"-psrfits\",          # Force the format (Safety for .sf files)\n",
    "            \"-time\", \"2.0\",      # 2.0s integration: Better than \"blocks\" for handling fast-moving RFI\n",
    "            \n",
    "            # --- THRESHOLD TUNING ---\n",
    "            \"-timesig\", \"25.0\",  # Reject time chunks > 10 sigma (removes impulsive RFI like lightning)\n",
    "            \"-freqsig\", \"8.0\",   # Reject freq channels > 4 sigma (removes narrowband RFI like GPS)\n",
    "            \n",
    "            # --- SIFTING PARAMETERS ---\n",
    "            \"-chanfrac\", \"0.7\",  # If 90% of channels in an interval are bad, kill the whole interval\n",
    "            \"-intfrac\", \"0.5\",   # If 30% of intervals in a channel are bad, kill the whole channel\n",
    "            \n",
    "            # --- FORMAT FLAGS (Legacy Parkes Safe-Mode) ---\n",
    "            \"-noweights\",\n",
    "            \"-noscales\",\n",
    "            \"-nooffsets\",\n",
    "            \n",
    "            # --- INPUT/OUTPUT ---\n",
    "            \"-o\", output_basename,\n",
    "            raw_filename\n",
    "        ]\n",
    "        # Run the command and check for errors\n",
    "        subprocess.run(command, check=True)\n",
    "        \n",
    "        print(\"\\n‚úÖ rfifind command finished executing.\")\n",
    "\n",
    "    # A more specific error if the 'rfifind' command itself isn't found\n",
    "    except FileNotFoundError:\n",
    "        print(\"\\n‚ùå ERROR: 'rfifind' command not found.\")\n",
    "        print(\"   Please ensure that your PRESTO environment is activated/sourced correctly.\")\n",
    "    # A more specific error if rfifind runs but returns an error code\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"\\n‚ùå An error occurred during rfifind execution: {e}\")\n",
    "    # A general catch-all for other unexpected errors\n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå An unexpected error occurred: {e}\")\n",
    "\n",
    "# --- 4. FINAL VERIFICATION ---\n",
    "# This final check confirms that the file either existed from the start\n",
    "# or was successfully created by the code block above.\n",
    "print(\"\\n--- Verifying Output ---\")\n",
    "if os.path.exists(mask_filename):\n",
    "    print(f\"‚úÖ SUCCESS! The mask file '{mask_filename}' is present and ready.\")\n",
    "else:\n",
    "    print(f\"‚ùå VALIDATION FAILED: The mask file '{mask_filename}' was not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c069a4-9e54-40d5-8a18-5ae5c2c54a7f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import subprocess\n",
    "\n",
    "# --- 1. CONFIGURATION ---\n",
    "# In WSL, D: drive is usually /mnt/d, E: is /mnt/e\n",
    "usb_path = \"/mnt/d/Presto_Project/thrd_psr\" \n",
    "\n",
    "# Ensure the USB directory exists\n",
    "if not os.path.exists(usb_path):\n",
    "    print(f\"‚ùå Error: USB path '{usb_path}' does not exist. Please create it or check the path.\")\n",
    "    exit()\n",
    "\n",
    "# Input data (Read from fast SSD)\n",
    "mask_filename = \"bpsr100613_beam08_rfifind.mask\"\n",
    "\n",
    "# Metadata from the .sf file header (HARDCODED for safety based on your provided info)\n",
    "total_samples_original = 8732672\n",
    "\n",
    "# Output Base (Write to Slow USB)\n",
    "# We join the USB path with the filename\n",
    "output_basename = os.path.join(usb_path, \"bpsr100613_beam08_topo\")\n",
    "\n",
    "# The de-dispersion plan (Standard L-Band Search)\n",
    "ddplan_stages = [\n",
    "    # Row 1: Covers DM 0 to 187.2 (Includes your target DM ~129)\n",
    "    {'low_dm': 0.000,   'high_dm': 187.200, 'ddm': 0.10, 'downsamp': 1, 'num_dms': 1872},\n",
    "    \n",
    "    # Row 2\n",
    "    {'low_dm': 187.200, 'high_dm': 332.800, 'ddm': 0.20, 'downsamp': 2, 'num_dms': 728},\n",
    "    \n",
    "    # Row 3\n",
    "    {'low_dm': 332.800, 'high_dm': 508.800, 'ddm': 0.50, 'downsamp': 4, 'num_dms': 352}\n",
    "]\n",
    "\n",
    "total_expected_dms = sum(stage['num_dms'] for stage in ddplan_stages)\n",
    "\n",
    "# --- 2. EXECUTION LOOP ---\n",
    "print(f\"--- Step 2: Multi-DM De-dispersion ---\")\n",
    "print(f\"Target: PSR J1048-45832 (NP)\")\n",
    "print(f\"Reading from: {raw_filename}\")\n",
    "print(f\"Writing to:   {usb_path}\")\n",
    "\n",
    "for i, stage in enumerate(ddplan_stages):\n",
    "\n",
    "    stage_basename = f\"{output_basename}_stage{i}\"\n",
    "    print(f\"\\n--- Processing Stage {i+1}/{len(ddplan_stages)} ---\")\n",
    "    \n",
    "    # Check for existing files\n",
    "    expected_files_for_stage = stage['num_dms']\n",
    "    # Note: We check the USB path for existing files\n",
    "    existing_files = glob.glob(f\"{stage_basename}*.inf\")\n",
    "    \n",
    "    if len(existing_files) >= expected_files_for_stage:\n",
    "        print(f\"‚úÖ Stage {i+1} already complete on USB. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    # --- CALCULATE NUMOUT  ---\n",
    "    # We must ensure the output length is an even number.\n",
    "    # Formula: Original Samples / Downsampling Factor\n",
    "    calculated_numout = int(total_samples_original / stage['downsamp'])\n",
    "    \n",
    "    # Ensure it's even \n",
    "    if calculated_numout % 2 != 0:\n",
    "        calculated_numout -= 1\n",
    "        \n",
    "    print(f\"   -> Downsample: {stage['downsamp']}\")\n",
    "    print(f\"   -> Calculated numout: {calculated_numout}\")\n",
    "\n",
    "    try:\n",
    "        command = [\n",
    "            \"prepsubband\",\n",
    "            # --- LAPTOP OPTIMIZATION ---\n",
    "            \"-ncpus\", \"4\",           # Use 4 cores\n",
    "            \n",
    "            # --- PHYSICS & SIGNAL PROCESSING ---\n",
    "            \"-psrfits\",              # Explicit format\n",
    "            \"-zerodm\",               # Removes terrestrial RFI (Zero-DM subtraction)\n",
    "            \"-nobary\",               # We stay topocentric for now (easier for initial search)\n",
    "            \"-numout\", str(calculated_numout), # Enforce file length\n",
    "            \n",
    "            # --- DDPLAN PARAMETERS ---\n",
    "            \"-lodm\", str(stage['low_dm']),\n",
    "            \"-dmstep\", str(stage['ddm']),\n",
    "            \"-numdms\", str(stage['num_dms']),\n",
    "            \"-downsamp\", str(stage['downsamp']),\n",
    "            \"-nsub\", \"32\",           # Standard subbanding\n",
    "            \n",
    "            # --- IO ---\n",
    "            \"-o\", stage_basename,    # Writes to USB path\n",
    "            \"-mask\", mask_filename,\n",
    "            raw_filename             # Reads from SSD\n",
    "        ]\n",
    "        custom_env = os.environ.copy()\n",
    "        custom_env[\"PRESTO\"] = \"presto\"\n",
    "        subprocess.run(command, \n",
    "                       check=True, \n",
    "                       #capture_output=True, \n",
    "                       env=custom_env\n",
    "                      )\n",
    "        print(f\"‚úÖ Stage {i+1} finished successfully.\")\n",
    "\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"\\n‚ùå PRESTO Error in stage {i+1}: {e}\")\n",
    "        break\n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå General Error: {e}\")\n",
    "        break\n",
    "\n",
    "# --- 3. VERIFICATION ---\n",
    "print(\"\\n--- Verifying Output on USB Drive ---\")\n",
    "# Check the USB path\n",
    "all_inf_files = glob.glob(f\"{output_basename}*.inf\")\n",
    "all_dat_files = glob.glob(f\"{output_basename}*.dat\")\n",
    "\n",
    "print(f\"Expected: {total_expected_dms}\")\n",
    "print(f\"Found .inf: {len(all_inf_files)}\")\n",
    "print(f\"Found .dat: {len(all_dat_files)}\")\n",
    "\n",
    "if len(all_dat_files) == total_expected_dms:\n",
    "    print(\"\\n‚úÖ SUCCESS! All data is safely stored on the USB drive.\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è  WARNING: File count mismatch. Check drive space or errors.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65f4351-e44f-4a5f-9577-c785ce2793aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import subprocess\n",
    "import re\n",
    "\n",
    "print(\"\\n--- Step 3 : Acceleration Search (Grid Search Mode) ---\")\n",
    "\n",
    "# --- 1. CONFIGURATION ---\n",
    "# Path to the data\n",
    "DATA_DIRECTORY = \"/mnt/d/Presto_Project/thrd_psr\" \n",
    "DAT_GLOB_PATTERN = os.path.join(DATA_DIRECTORY, \"bpsr100613_beam08_topo_*.dat\")\n",
    "\n",
    "# --- GRID SEARCH STRATEGIES ---\n",
    "# We run ALL of these on every single file.\n",
    "SEARCH_STRATEGIES = [\n",
    "    # Strategy 1: The \"Deep & Slow\" (Standard Pulsars)\n",
    "    # Catches slow, isolated pulsars and long-period signals.\n",
    "    {\"zmax\": 0,   \"numharm\": 8,  \"flo\": 0.1, \"suffix\": \"Iso_Slow\"},\n",
    "    \n",
    "    # Strategy 2: The \"Binary\" (Standard Binaries)\n",
    "    # Catches normal pulsars in wide/moderate orbits.\n",
    "    {\"zmax\": 100, \"numharm\": 8,  \"flo\": 1.0, \"suffix\": \"Binary\"},\n",
    "    \n",
    "    # Strategy 3: The \"MSP/Extreme\" (Fast & Tight Orbits)\n",
    "    # Catches Millisecond Pulsars and tight binaries (Black Widows).\n",
    "    {\"zmax\": 200, \"numharm\": 16, \"flo\": 1.0, \"suffix\": \"MSP_Fast\"}\n",
    "]\n",
    "# --- 2. PRE-FLIGHT CHECK ---\n",
    "dat_files_to_search = sorted(glob.glob(DAT_GLOB_PATTERN))\n",
    "\n",
    "if not dat_files_to_search:\n",
    "    print(f\"‚ùå ERROR: No .dat files found in {DATA_DIRECTORY}.\")\n",
    "    print(\"   Please wait for Step 2 to finish completely.\")\n",
    "else:\n",
    "    print(f\"‚úÖ Found {len(dat_files_to_search)} .dat files.\")\n",
    "    print(f\"‚öôÔ∏è  Each file will undergo {len(SEARCH_STRATEGIES)} distinct search strategies.\")\n",
    "    \n",
    "    # --- 3. EXECUTION LOOP (Per File) ---\n",
    "    for dat_filename in dat_files_to_search:\n",
    "        \n",
    "        filename_only = os.path.basename(dat_filename)\n",
    "        print(f\"\\n==================================================\")\n",
    "        print(f\"üìÇ Processing: {filename_only}\")\n",
    "        \n",
    "        # Determine DM just for logging (Grid Search ignores this for decision making)\n",
    "        try:\n",
    "            dm_string = re.search(r\"DM(\\d+\\.\\d+)\", dat_filename).group(1)\n",
    "            current_dm = float(dm_string)\n",
    "            print(f\"   DM: {current_dm:.2f}\")\n",
    "        except:\n",
    "            current_dm = 0.0\n",
    "\n",
    "        # --- GRID SEARCH LOOP (Per Strategy) ---\n",
    "        for strategy in SEARCH_STRATEGIES:\n",
    "            zmax = strategy['zmax']\n",
    "            numharm = strategy['numharm']\n",
    "            flo = strategy['flo']\n",
    "            name = strategy['suffix']\n",
    "\n",
    "            print(f\"   --> Strategy: {name} (zmax={zmax}, numharm={numharm}, flo={flo})\")\n",
    "\n",
    "            try:\n",
    "                # --- CHECK EXISTENCE ---\n",
    "                base_no_ext = os.path.splitext(dat_filename)[0]\n",
    "                # PRESTO output naming rule: filename_ACCEL_zmax.cand\n",
    "                expected_cand_file = f\"{base_no_ext}_ACCEL_{zmax}.cand\"\n",
    "\n",
    "                if os.path.exists(expected_cand_file) and os.path.getsize(expected_cand_file) > 0:\n",
    "                    print(f\"       ‚úÖ Output exists ({name}). Skipping.\")\n",
    "                    continue\n",
    "\n",
    "                # --- RUN ACCELSEARCH ---\n",
    "                command = [\n",
    "                    \"accelsearch\",\n",
    "                    \"-ncpus\", \"4\",       # Safe for SSD\n",
    "                    #\"-inmem\",           # Keep commented out if RAM is tight and RAM is tight in my case\n",
    "                    \"-numharm\", str(numharm),\n",
    "                    \"-zmax\", str(zmax),\n",
    "                    \"-flo\", str(flo),\n",
    "                    \"-sigma\", \"2.0\",\n",
    "                    dat_filename\n",
    "                ]\n",
    "                \n",
    "                custom_env = os.environ.copy()\n",
    "                custom_env[\"PRESTO\"] = \"presto\"\n",
    "\n",
    "                # Run silently unless error\n",
    "                subprocess.run(\n",
    "                    command, check=True, env=custom_env, capture_output=True, text=True\n",
    "                )\n",
    "                print(f\"       ‚úÖ Search Complete.\")\n",
    "\n",
    "            except subprocess.CalledProcessError as e:\n",
    "                print(f\"       ‚ùå PRESTO Error in strategy {name}:\\n{e.stderr}\")\n",
    "            except Exception as e:\n",
    "                print(f\"       ‚ùå System Error: {e}\")\n",
    "\n",
    "        # --- FILE CLEANUP (Run only after ALL strategies are done for this file) ---\n",
    "        # NOTE: Only uncomment this if you are sure you don't need the .dat file anymore.\n",
    "        # Since we are running multiple strategies, we must not delete it inside the inner loop.\n",
    "        if os.path.exists(dat_filename):\n",
    "            # os.remove(dat_filename)\n",
    "            # print(f\"üóëÔ∏è  Deleted .dat file to free space.\")\n",
    "            pass\n",
    "    print(\"\\nüéâ --- All Searches Complete! --- üéâ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7735f90-0f0a-4646-ae78-2c1bff673b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "print(\"\\n--- Step 4: Phase-Specific Sifting ---\")\n",
    "\n",
    "# --- 1. CONFIGURATION ---\n",
    "# Path to your SSD processing folder\n",
    "DATA_DIR = \"/mnt/d/Presto_Project/thrd_psr\" \n",
    "SIFTING_COMMAND = \"ACCEL_sift.py\" \n",
    "\n",
    "# Check Input Directory\n",
    "if not os.path.exists(DATA_DIR):\n",
    "    print(f\"‚ùå ERROR: Data directory '{DATA_DIR}' not found.\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# ---  MAPPING FOR GRID SEARCH ---\n",
    "# This matches the zmax values you used in Step 3.\n",
    "phase_mapping = {\n",
    "    # Strategy 1: Standard/Slow (zmax=0)\n",
    "    \"Iso_Slow_Search\": \"*_ACCEL_0.cand\",\n",
    "    \n",
    "    # Strategy 2: Binary (zmax=100)\n",
    "    \"Binary_Search\":   \"*_ACCEL_100.cand\",\n",
    "    \n",
    "    # Strategy 3: MSP/Extreme (zmax=200)\n",
    "    \"MSP_Fast_Search\": \"*_ACCEL_200.cand\"\n",
    "}\n",
    "\n",
    "# --- 2. EXECUTION LOOP ---\n",
    "for phase_name, file_pattern in phase_mapping.items():\n",
    "    try:\n",
    "        print(f\"\\n--- Processing Sifting Phase: '{phase_name}' ---\")\n",
    "        \n",
    "        # Change Directory to Data Dir (Crucial for ACCEL_sift to find .inf files)\n",
    "        os.chdir(DATA_DIR)\n",
    "\n",
    "        # Define output file\n",
    "        sifted_output_file = f\"Sifted_Candidates_{phase_name}.txt\"\n",
    "\n",
    "        # Check if output exists to save time\n",
    "        if os.path.exists(sifted_output_file) and os.path.getsize(sifted_output_file) > 0:\n",
    "            print(f\"‚úÖ Sifted file '{sifted_output_file}' already exists. Skipping.\")\n",
    "            continue \n",
    "\n",
    "        # Find the files using the pattern\n",
    "        cand_files_for_phase = glob.glob(file_pattern)\n",
    "\n",
    "        if not cand_files_for_phase:\n",
    "            print(f\"‚ö†Ô∏è  WARNING: No files found for pattern '{file_pattern}'.\")\n",
    "            print(f\"    If you didn't run this specific Step 3 strategy, this is normal.\")\n",
    "            continue\n",
    "\n",
    "        print(f\"    Found {len(cand_files_for_phase)} candidate files. Running Sift...\")\n",
    "        \n",
    "        # --- EXECUTION ---\n",
    "        # Construct command\n",
    "        command = [SIFTING_COMMAND] + cand_files_for_phase\n",
    "        custom_env = os.environ.copy()\n",
    "        custom_env[\"PRESTO\"] = \"presto\"\n",
    "\n",
    "        # Run command\n",
    "        # Note: We use cwd=DATA_DIR so filenames in 'command' can be relative (shorter)\n",
    "        # This helps avoid the \"Argument list too long\" error\n",
    "        result = subprocess.run(\n",
    "            command,\n",
    "            check=True,\n",
    "            capture_output=True, # Sifting prints results to STDOUT, we want to capture it\n",
    "            text=True,\n",
    "            env=custom_env,\n",
    "            cwd=DATA_DIR \n",
    "        )\n",
    "        \n",
    "        sifted_candidates_output = result.stdout\n",
    "\n",
    "        # --- PARSING RESULTS ---\n",
    "        # We filter the output to count how many candidates survived\n",
    "        # PRESTO output lines starting with # are headers.\n",
    "        candidate_lines = [\n",
    "            line for line in sifted_candidates_output.strip().split('\\n')\n",
    "            if line.strip() and not line.startswith('#') and \"DM\" in line\n",
    "        ]\n",
    "        num_cands = len(candidate_lines)\n",
    "\n",
    "        print(f\"    ‚úÖ Sift complete. Found {num_cands} unique candidates.\")\n",
    "\n",
    "        # Save to file\n",
    "        with open(sifted_output_file, 'w') as f:\n",
    "            f.write(sifted_candidates_output)\n",
    "        \n",
    "        if num_cands > 0:\n",
    "            print(f\"    üéâ RESULTS SAVED to: {sifted_output_file}\")\n",
    "        else:\n",
    "            print(f\"    üìâ No candidates passed the filter.\")\n",
    "\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"\\n  ‚ùå Error during sifting phase '{phase_name}'.\")\n",
    "        print(f\"  STDERR: {e.stderr.strip()}\")\n",
    "        \n",
    "    except OSError as e:\n",
    "        if e.errno == 7: \n",
    "            print(f\"\\n  ‚ùå ERROR: Argument list too long.\")\n",
    "            print(f\"     You have {len(cand_files_for_phase)} files, which exceeds WSL limits.\")\n",
    "            print(\"     Advice: Step 3 might have produced too many candidates, or you need to split this batch manually.\")\n",
    "        else:\n",
    "            print(f\"\\n  ‚ùå OS Error: {e}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\n  ‚ùå Unexpected error: {e}\")\n",
    "\n",
    "print(\"\\nüéâ --- All sifting phases complete! --- üéâ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9636563c-fa9f-4c1c-a0b3-cd74ba1f57c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import glob\n",
    "import re\n",
    "import shutil\n",
    "import sys\n",
    "\n",
    "print(\"--- Step 5: Folding Candidates ---\")\n",
    "\n",
    "# --- 1. CONFIGURATION ---\n",
    "# A. Parent Folder\n",
    "RAW_DATA_DIR = \"/mnt/d/Presto_Project/thrd_psr\" \n",
    "\n",
    "# B. Subfolder\n",
    "CANDIDATE_DIR = RAW_DATA_DIR \n",
    "\n",
    "# C. Output Folder\n",
    "OUTPUT_DIRECTORY = os.path.join(RAW_DATA_DIR, \"CANDIDATE_PLOTS\")\n",
    "os.makedirs(OUTPUT_DIRECTORY, exist_ok=True)\n",
    "\n",
    "# FILENAMES\n",
    "RAW_FILENAME = \"bpsr100613_052818_beam08.sf\"\n",
    "MASK_FILENAME = \"bpsr100613_beam08_rfifind.mask\"\n",
    "\n",
    "# COMMANDS\n",
    "PREPFOLD_COMMAND = \"prepfold\"\n",
    "PS2PDF_COMMAND = \"ps2pdf\"\n",
    "\n",
    "# --- Match the keys from Step 4 Grid Search ---\n",
    "phase_suffixes = [\"Iso_Slow_Search\", \"Binary_Search\", \"MSP_Fast_Search\"]\n",
    "\n",
    "# --- 2. CHECK RAW DATA EXISTENCE ---\n",
    "raw_file_path = os.path.join(RAW_DATA_DIR, RAW_FILENAME)\n",
    "mask_file_path = os.path.join(RAW_DATA_DIR, MASK_FILENAME)\n",
    "\n",
    "if not os.path.exists(raw_file_path):\n",
    "    print(f\"‚ùå ERROR: Raw data not found: {raw_file_path}\")\n",
    "    sys.exit(1)\n",
    "if not os.path.exists(mask_file_path):\n",
    "    print(f\"‚ùå ERROR: Mask not found: {mask_file_path}\")\n",
    "    sys.exit(1)\n",
    "\n",
    "print(f\"üìÇ Candidates: {CANDIDATE_DIR}\")\n",
    "print(f\"üìÇ Output:     {OUTPUT_DIRECTORY}\")\n",
    "\n",
    "# --- 3. EXECUTION LOOP ---\n",
    "for suffix in phase_suffixes:\n",
    "    \n",
    "    sifted_list_path = os.path.join(CANDIDATE_DIR, f\"Sifted_Candidates_{suffix}.txt\")\n",
    "    print(f\"\\n--- Processing Sifted File: '{os.path.basename(sifted_list_path)}' ---\")\n",
    "\n",
    "    if not os.path.exists(sifted_list_path):\n",
    "        print(f\"  ‚ö†Ô∏è  File not found. (Did Step 4 generate candidates for this strategy?)\")\n",
    "        continue\n",
    "\n",
    "    # --- PARSING THE FILE ---\n",
    "    candidates_to_fold = []\n",
    "    with open(sifted_list_path, 'r') as f:\n",
    "        for line in f:\n",
    "            if line.startswith('#') or not line.strip(): \n",
    "                continue\n",
    "            \n",
    "            parts = line.split()\n",
    "            \n",
    "            # Skip Headers\n",
    "            if \"File:Candidate\" in parts[0] or parts[0] == \"DM\": \n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                address = parts[0]\n",
    "                if \":\" not in address: continue\n",
    "\n",
    "                cand_file_name, cand_num = address.split(':')\n",
    "\n",
    "                # Fix extension if missing\n",
    "                if not cand_file_name.endswith(\".cand\"):\n",
    "                    cand_file_name += \".cand\"\n",
    "                    \n",
    "                full_cand_path = os.path.join(CANDIDATE_DIR, cand_file_name)\n",
    "                \n",
    "                candidates_to_fold.append({\n",
    "                    'path': full_cand_path,\n",
    "                    'num': cand_num,\n",
    "                    'shortname': cand_file_name\n",
    "                })\n",
    "            except (ValueError, IndexError):\n",
    "                continue\n",
    "    \n",
    "    num_cands = len(candidates_to_fold)\n",
    "    print(f\"  Found {num_cands} candidates to fold.\")\n",
    "    \n",
    "    # --- FOLDING LOOP ---\n",
    "    for i, cand in enumerate(candidates_to_fold):\n",
    "        cand_path = cand['path']\n",
    "        cand_num = cand['num']\n",
    "        \n",
    "        dm_match = re.search(r'DM(\\d+\\.\\d+)', cand['shortname'])\n",
    "        dm_val = dm_match.group(1) if dm_match else \"0.00\"\n",
    "        \n",
    "        output_basename = f\"Fold_{suffix}_DM{dm_val}_Cand{cand_num}\"\n",
    "        final_pdf_path = os.path.join(OUTPUT_DIRECTORY, f\"{output_basename}.pdf\")\n",
    "\n",
    "        if os.path.exists(final_pdf_path):\n",
    "            print(f\"    ‚úÖ Plot exists for Cand {cand_num} (DM {dm_val}). Skipping.\")\n",
    "            continue\n",
    "\n",
    "        print(f\"    ‚öôÔ∏è  [{i+1}/{num_cands}] Folding Cand {cand_num} (DM {dm_val})...\")\n",
    "\n",
    "        try:\n",
    "            command = [\n",
    "                PREPFOLD_COMMAND,\n",
    "                \"-topo\", \n",
    "                \"-noxwin\", \n",
    "                \"-mask\", mask_file_path,\n",
    "\n",
    "                # Removed -nosearch so PRESTO can optimize\n",
    "                # Disabled -zerodm for J0437\n",
    "                \"-zerodm\", \n",
    "                \"-n\", \"128\", \n",
    "                \"-nsub\", \"64\",\n",
    "                \"-accelfile\", cand_path,\n",
    "                \"-accelcand\", cand_num,\n",
    "                \"-o\", output_basename,\n",
    "                raw_file_path\n",
    "            ]\n",
    "            \n",
    "            custom_env = os.environ.copy()\n",
    "            custom_env[\"PRESTO\"] = \"presto\"\n",
    "\n",
    "            # Run PRESTO\n",
    "            subprocess.run(\n",
    "                command, \n",
    "                check=True, \n",
    "                #capture_output=True, \n",
    "                text=True, \n",
    "                env=custom_env\n",
    "            )\n",
    "            \n",
    "            # Convert to PDF\n",
    "            ps_files = glob.glob(f\"{output_basename}*.ps\")\n",
    "            if ps_files:\n",
    "                ps_file = ps_files[0]\n",
    "                subprocess.run([PS2PDF_COMMAND, ps_file], check=True)\n",
    "                generated_pdf = ps_file.replace(\".ps\", \".pdf\")\n",
    "                if os.path.exists(generated_pdf):\n",
    "                    shutil.move(generated_pdf, final_pdf_path)\n",
    "                    print(f\"       -> Saved: {os.path.basename(final_pdf_path)}\")\n",
    "                    os.remove(ps_file)\n",
    "            else:\n",
    "                print(\"    ‚ùå Error: No .ps file generated.\")\n",
    "\n",
    "        except subprocess.CalledProcessError:\n",
    "            print(f\"    ‚ùå Prepfold failed for Cand {cand_num}.\")\n",
    "        except Exception as e:\n",
    "            print(f\"    ‚ùå System Error: {e}\")\n",
    "\n",
    "print(\"\\nüéâ --- Pipeline Finished! Check the 'CANDIDATE_PLOTS' folder. --- üéâ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454c6971-d6a1-49b2-9e1d-14873df2ba1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2f45c6-f5b7-4f05-92e5-611ae750f40d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f9b031-23b3-498b-8ace-2189b2e9b663",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f022d1-9b37-42e8-90b1-869970dd9eb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd39ef7-631b-45bf-8c67-eaeacdddce16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf6963f-5e43-41d7-b3c6-abf6e1a78f94",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PRESTO Project Environment",
   "language": "python",
   "name": "presto_proj"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
